---
title: "R Notebook"
output: html_notebook
---

Common Distributions

Discrete and Continuous Variables

> Numeric Data - discrete / continuous
> Categorical Data - Nominal / ordinal (an order like days of the week)

> Discrete - countable and finite
> Continuous - uncountable


Variables

- number of people in my survey who love the colour blue = _discrete value_
- height of people in Scotland                           = _continuous_
- age (years)                                            = _continuous numeric_
- age (group)                                            = _ordinal categorical (child, adult, senior)_
- number of people in a household                        = _discrete numeric_
- height                                                 = _continuous numeric_
- weight                                                 = _continuous numeric_
- shoe size (uk)                                         = _ordinal categoric_
- foot size                                              = _continuous numeric_
- vegetarian                                             = _nominal categoric (binary)_
_
## Probability mass and probability density functions

_discrete probability distribution_ is a probability distribution of a discrete vairable

heads or tails, discrete number of outcomes

_probability mass function_ --> prob distribution of a discrete variable

_probability density function_ --> prob distribution of a continuous variable


What is the probability of heights in the range from 174.22cm to 178.91cm in the dataset?
Based on this data, what is the probability that I measure someone's hwight in the range from 174.22cm to 178.91cm

In the case of pmf vs pdf, 
while we  can measure probabilities for specific discrete values of a pmf, 
we can't for pdf. 
We look instead at the probability of a range of values


Rules for discrete probability distributions

- outcome = x-axis
- probabilities of that outcome occuring = y-axis (pmfs)
- the sum of all probabilities must be 1
- each probability must be betwen 0 and 1


Rules for continuous probability distributions

- outcome = x-axis
- probability density = y-axis
- the sum of all probabilities must be 1 (the area under the curve defined by a probability density function must be 1)
- each probability must be betwen 0 and 1


Discrete Distributions

Discrete uniform
```{r}
library(tidyverse)
```


```{r}
source("prob.R")
```


```{r}
tosscoin(3) %>% 
  mutate(label = str_c(toss1, toss2, toss3, sep = "")) %>% 
  mutate(p = 1 / n()) %>% 
  ggplot(aes(x = label,
             y = p)) +
  geom_col()
```


```{r}
rolldie(1) %>%
  mutate(p = 1 / n()) %>% 
  ggplot(aes(x = X1,
             y = p)) +
  geom_col()
```

There is _another_ way we can explore probability distributions

Cumulative Distribution Functions
F(1) = 1/6 = p(1 or less)
F(2) = 1/6 + 1/6 = p(2 or less)

```{r}
# cdf for rolling one die

rolldie(1) %>% 
  mutate(p = 1 / n()) %>% 
  mutate(F_x = cumsum(p)) %>% 
  ggplot(aes(x = X1,
             y = F_x)) +
  geom_step()
```

getting individual probabilities from cdfs

p(3) = F(3) - F(2)
p(3) = 0.5  - 0.33333333
p(3) = 0.166666667

p(4) = F(4) - F(3)
p(4) = 0.66666667 - 0.5
p(4) = 0.166666667


Continuous Distributions

Continuous uniform

lengths of 'brain breaks' at CodeClan were monitored for a week.
They were found to be distributed uniformly (equal p) between 5 mins and 22 mins.

length = l 

l is continuous (5 mins, 7.13576 mins, 21.9 mins)

What will the probability density function look like for the random variable l?

R useful distribution functions:

> p - cumulative density function
> q - quantile
> r - random numbers
> d - distribution

```{r}
brain_break <- tibble(
  length = seq(4, 23, 0.1),
  f_length = dunif(x = length, min = 5, max = 22)
)

# probability density function (we're looking at continuous var)
brain_break %>% 
  ggplot(aes(x = length,
             y = f_length)) + 
  geom_line()

brain_break %>% 
  mutate(F_length = punif(q = length, min = 5, max = 22)) %>% 
  ggplot(aes(x = length,
             y = F_length)) + 
  geom_line()

```


What is the probability of a brain break lasting between 8.4 and 10.7 mins?
F(10.7) - F(8.4)
```{r}
f_10_7 <- punif(
  q = 10.7,
  min = 5,
  max = 22
)

f_8_4 <- punif(
  q = 8.4,
  min = 5,
  max = 22
)

f_10_7 - f_8_4
```
There is ~ 14% chance of getting a brain break between 8.4 - 10.7 mins

```{r}
brain_break %>% 
  ggplot(aes(x = length,
             y = f_length)) +
  geom_line() +
  geom_ribbon(aes(ymin = 0,
                  ymax = ifelse(
                    length >= 8.4 & length <= 10.7,
                    f_length,
                    0)),
              fill = "red",
              alpha = 0.6)
```


Normal Distribution

> very prevelant in `nature`
> symmetric
> large peak
> defined by mean and sd

```{r}
three_norms <- tibble(
  x = seq(0, 100, 1),
  f1_x = dnorm(x = x, mean = 50, sd = 1),
  f2_x = dnorm(x = x, mean = 50, sd = 5),
  f3_x = dnorm(x = x, mean = 50, sd = 10)
)

three_norms %>% 
  ggplot() +
  geom_line(aes(x = x,
                y = f1_x),
            col = "red") +
  geom_line(aes(x = x,
                y = f2_x),
            col = "black") +
  geom_line(aes(x = x,
                y = f3_x),
            col = "blue") 
```

A thing to notice os that for very small values of x (or very distant from the mean)
for a normal distribution these will be _non-zero_
They'll be very very very small, but _not_ p = 0



```{r}
three_norms <- tibble(
  x = seq(0, 100, 1),
  f1_x = dnorm(x = x, mean = 25, sd = 1),
  f2_x = dnorm(x = x, mean = 25, sd = 5),
  f3_x = dnorm(x = x, mean = 25, sd = 10)
)

three_norms %>% 
  ggplot() +
  geom_line(aes(x = x,
                y = f1_x),
            col = "red") +
  geom_line(aes(x = x,
                y = f2_x),
            col = "black") +
  geom_line(aes(x = x,
                y = f3_x),
            col = "blue")
```

A lot of what we see in inferential statistics
is that taking repeated samples of a population leads to a _normal distribution_


How can we tell if our data is normally distributed?

> qqplots (quantile quantile plots)
> normailty tests
> look at a normal distribution vs our data
> fit a normal distribution to a data set

```{r}
jobs <- read_csv("data/TyrellCorpJobs.csv") %>% clean_names() %>% select(-1)
```

Looking at just the accounting department,
is the data _normally_ distrubuted?
```{r}
accounting_position_stats <- jobs %>% 
  filter(position == "Accounting") %>% 
  summarise(num = n(),
            mean = mean(salary),
            sd_sal = sd(salary))

accounting_position_stats
```

Overlaying a _normal_ distribution

```{r}
# 1. plot histogram
# 2. change the metric of the y-axis in histogram
# 3. use stat_function and pre-calculated steps to overlay a normal distribution

jobs %>% 
  filter(position == "Accounting") %>% 
  ggplot(aes(x = salary)) +
  geom_histogram(aes(y = ..density..)) +
  stat_function(
    fun = ~dnorm(., mean = accounting_position_stats$mean,
                 sd = accounting_position_stats$sd_sal)
  )
```


"Standard Normal"
scaled so that mean = 0, sd = 1

standardised variable (tool to describe normal distributions)

z of a value = value - mean / standard deviation

Something that tells us how far away we are from the mean in units of standard deviation

z = 1.3 then the value is 1.3 * sd away from the mean
z = 3 would be a value 3 * sd away from the mean

This is another definition of an outlier
> a value 1.5 * IQR above Q3 or below Q1
> any value with a z above or below 3


```{r}
management_scaled <- jobs %>% 
  filter(position == "Management") %>%
  # scale automatically calculated z scores
  mutate(z_salary = scale(salary)) %>% 
  mutate(mean_sal = mean(salary))

management_scaled %>% 
  filter(abs(z_salary) > 2)
```
This person is earning 3.67 * sd of mean salary


Shading the standard normal
```{r}
shade_standard_normal <- function(shade_from, shade_to){
  standard_normal <- tibble(
    z = seq(from = -4, to = 4, by = 0.001),
    f_z = dnorm(x = z)
  )
  standard_normal %>%
    ggplot(aes(x = z, y = f_z)) +
    geom_line() +
    geom_ribbon(aes(ymin = 0, ymax = ifelse(z >= shade_from & z <= shade_to, f_z, 0)), fill = "red", alpha = 0.6)
}

shade_standard_normal(shade_from = -Inf, shade_to = 0)
```


The emperical 3-sigma rule

Most values lie within 3 standard deviations of the mean ~ 99.7%

Let's calculate how many values should lie within 1 sd of the mean for a standard normal distribution

```{r}

# one sd above - one sd below
100 * (pnorm(q =1) - pnorm(q = -1))
```
68% of our data should lie within one sd of the mean


Let's calculate how many values should lie within 2 sd of the mean for a standard normal distribution

```{r}

# two sd above - two sd below
100 * (pnorm(q =2) - pnorm(q = -2))
```
95% of our data should lie within one sd of the mean

```{r}
shade_standard_normal(-2, 2)
```
For data that is normally distributed we expect:
> 68% values lie within 1 sd of the mean
> 95% values lie within 2 sd of the mean
> 99.7% values lie within 3 sd of the mean





